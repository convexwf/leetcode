# [146.LRU Cache](https://leetcode.com/problems/lru-cache/description/)

## Description

**Tags**: design

**Companies**: amazon,bloomberg,facebook,google,microsoft,palantir,snapchat,twitter,uber,yahoo,zenefits

|  Category  |   Difficulty    | Likes | Dislikes |
| :--------: | :-------------: | :---: | :------: |
| algorithms | Medium (42.07%) | 20033 |   948    |


<p>Design a data structure that follows the constraints of a <strong><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU" target="_blank">Least Recently Used (LRU) cache</a></strong>.</p>
<p>Implement the <code>LRUCache</code> class:</p>
<ul>
  <li><code>LRUCache(int capacity)</code> Initialize the LRU cache with <strong>positive</strong> size <code>capacity</code>.</li>
  <li><code>int get(int key)</code> Return the value of the <code>key</code> if the key exists, otherwise return <code>-1</code>.</li>
  <li><code>void put(int key, int value)</code> Update the value of the <code>key</code> if the <code>key</code> exists. Otherwise, add the <code>key-value</code> pair to the cache. If the number of keys exceeds the <code>capacity</code> from this operation, <strong>evict</strong> the least recently used key.</li>
</ul>
<p>The functions <code>get</code> and <code>put</code> must each run in <code>O(1)</code> average time complexity.</p>
<p>&nbsp;</p>
<p><strong class="example">Example 1:</strong></p>
<pre><code><strong>Input</strong>
[&quot;LRUCache&quot;, &quot;put&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;get&quot;, &quot;get&quot;]
[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]
<strong>Output</strong>
[null, null, null, 1, null, -1, null, -1, 3, 4]
<strong>Explanation</strong>
LRUCache lRUCache = new LRUCache(2);
lRUCache.put(1, 1); // cache is {1=1}
lRUCache.put(2, 2); // cache is {1=1, 2=2}
lRUCache.get(1);    // return 1
lRUCache.put(3, 3); // LRU key was 2, evicts key 2, cache is {1=1, 3=3}
lRUCache.get(2);    // returns -1 (not found)
lRUCache.put(4, 4); // LRU key was 1, evicts key 1, cache is {4=4, 3=3}
lRUCache.get(1);    // return -1 (not found)
lRUCache.get(3);    // return 3
lRUCache.get(4);    // return 4</code></pre>
<p>&nbsp;</p>
<p><strong>Constraints:</strong></p>
<ul>
  <li><code>1 &lt;= capacity &lt;= 3000</code></li>
  <li><code>0 &lt;= key &lt;= 10<sup>4</sup></code></li>
  <li><code>0 &lt;= value &lt;= 10<sup>5</sup></code></li>
  <li>At most <code>2 * 10<sup>5</sup></code> calls will be made to <code>get</code> and <code>put</code>.</li>
</ul>

## Solution

**题目描述**

设计并实现一个 `LRU(Least Recently Used)` 数据结构。

实现 `LRUCache` 类：

- `LRUCache(int capacity)` 以正整数作为容量 `capacity` 初始化 `LRU` 缓存。
- `int get(int key)` 如果关键字 `key` 存在于缓存中，则返回关键字的值，否则返回 `-1` 。
- `void put(int key, int value)` 如果 `key` 存在，更新 `value` ；如果 `key` 不存在，则插入该组 `key-value` 。当缓存容量达到上限时，应该在插入新数据之前，将最久未使用的数据删除。注意，`put` 和 `get` 操作都属于数据使用操作。

要求 `get` 和 `put` 操作的时间复杂度均为 `O(1)`。

**相关题目**

- [0460.LFU Cache](./0460.lfu-cache.md)

**解题思路**

1. 双向链表+哈希表
   - 为了能够在 `O(1)` 时间内找到最近最少使用的节点，需要维护一个双向链表，链表头部表示最近使用的节点，链表尾部表示最久未使用的节点。
     - 当某个节点被访问时(插入或者更新)，将其移动至链表头部，移动操作时间复杂度为 `O(1)`。为了使访问操作时间复杂度为 `O(1)`，需要使用哈希表存储节点的地址。
     - 当链表长度超过容量时，直接删除链表尾部节点，删除操作时间复杂度为 `O(1)`。
     - 双向链表需要在头部和尾部增加一个 `dummy node`，减少边界处理复杂度。
   - 维护一个哈希表存储 `key` 对应的双向链表节点的地址。
     - 当某个节点被访问时，哈希表不需要更新。
     - 当某个新节点被插入时，哈希表需要更新，需要在双向链表中插入新节点，并把新节点的地址存入哈希表。
     - 当某个节点被删除时，哈希表需要更新，需要在双向链表中删除节点，并把哈希表中的对应 `key` 删除。
   - 具体实现
     - `LRUCache(int capacity)` 初始化哈希表和双向链表，维护一个变量表示当前还能容纳的节点数量。
     - `get(int key)` : 首先判断 `key` 是否存在于哈希表中
       - 如果存在，将节点移动至链表头部，并返回 `value`。
       - 如果不存在，返回 `-1`。
     - `put(int key, int value)` : 首先判断 `key` 是否存在于哈希表中
       - 如果存在，更新节点的 `value`，并将节点移动至链表头部。
       - 如果不存在，新建节点并移动至链表头部，更新哈希表。
       - 如果新加入的节点导致超过了最大容量，更新哈希表，删除链表结尾节点。
     - Tips: 添加节点时先更新链表再更新哈希表，删除节点时先更新哈希表再更新链表。
   - 时间复杂度：`put` 和 `get` 操作均为 `O(1)`。

**标签**

- design

<!-- code start -->
## Code

### C++

```cpp
// 1. 双向链表+哈希表
// 2020-09-18 submission
// 22/22 cases passed
// Runtime: 483 ms, faster than 66.16% of cpp online submissions.
// Memory Usage: 165 MB, less than 82.01% of cpp online submissions.
struct LinkedNode
{
    int key;
    int value;
    struct LinkedNode* next;
    struct LinkedNode* prev;
    explicit LinkedNode(int key, int value) : key(key), value(value), next(nullptr), prev(nullptr) {
    }
};

class LRUCache {
public:
    LRUCache(int capacity) {
        this->size = 0;
        this->capacity = capacity;
        this->dummyHead = new LinkedNode(0, 0);
        this->dummyTail = new LinkedNode(0, 0);
        this->dummyHead->next = this->dummyTail;
        this->dummyTail->prev = this->dummyHead;
    }

    int get(int key) {
        if (!cache.count(key))
            return -1;
        else {
            LinkedNode* node = cache[key];
            this->moveNodeToHead(node);
            return node->value;
        }
    }

    void put(int key, int value) {
        if (cache.count(key)) {
            cache[key]->value = value;
            this->moveNodeToHead(cache[key]);
        }
        else {
            LinkedNode* node = new LinkedNode(key, value);
            this->addNodeToHead(node);
            cache[key] = node;
            ++size;
            while (capacity < size) {
                LinkedNode* tailNode = this->dummyTail->prev;
                cache.erase(tailNode->key);
                this->removeNodeFromList(tailNode);
                --size;
            }
        }
    }

private:
    int addNodeToHead(LinkedNode* node) {
        if (node == nullptr) {
            return -1;
        }
        node->next = this->dummyHead->next;
        this->dummyHead->next = node;
        node->prev = this->dummyHead;
        node->next->prev = node;
        return 0;
    }

    int moveNodeToHead(LinkedNode* node) {
        if (node == nullptr) {
            return -1;
        }
        node->next->prev = node->prev;
        node->prev->next = node->next;
        return addNodeToHead(node);
    }

    int removeNodeFromList(LinkedNode* node) {
        if (node == nullptr) {
            return -1;
        }
        node->next->prev = node->prev;
        node->prev->next = node->next;
        delete node;
        return 0;
    }

private:
    uint32_t size;
    uint32_t capacity;
    struct LinkedNode* dummyHead;
    struct LinkedNode* dummyTail;
    std::unordered_map<int, struct LinkedNode*> cache;
};

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache* obj = new LRUCache(capacity);
 * int param_1 = obj->get(key);
 * obj->put(key,value);
 */
```

<!-- code end -->
