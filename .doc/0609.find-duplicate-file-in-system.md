# [609.Find Duplicate File in System](https://leetcode.com/problems/find-duplicate-file-in-system/description/)

## Description

**Tags**: hash-table,string

**Companies**: Unknown

|  Category  |   Difficulty    | Likes | Dislikes |
| :--------: | :-------------: | :---: | :------: |
| algorithms | Medium (67.68%) | 1459  |   1625   |

<p>Given a list <code>paths</code> of directory info, including the directory path, and all the files with contents in this directory, return <em>all the duplicate files in the file system in terms of their paths</em>. You may return the answer in <strong>any order</strong>.</p>
<p>A group of duplicate files consists of at least two files that have the same content.</p>
<p>A single directory info string in the input list has the following format:</p>
<ul>
  <li><code>&quot;root/d1/d2/.../dm f1.txt(f1_content) f2.txt(f2_content) ... fn.txt(fn_content)&quot;</code></li>
</ul>
<p>It means there are <code>n</code> files <code>(f1.txt, f2.txt ... fn.txt)</code> with content <code>(f1_content, f2_content ... fn_content)</code> respectively in the directory &quot;<code>root/d1/d2/.../dm&quot;</code>. Note that <code>n &gt;= 1</code> and <code>m &gt;= 0</code>. If <code>m = 0</code>, it means the directory is just the root directory.</p>
<p>The output is a list of groups of duplicate file paths. For each group, it contains all the file paths of the files that have the same content. A file path is a string that has the following format:</p>
<ul>
  <li><code>&quot;directory_path/file_name.txt&quot;</code></li>
</ul>
<p>&nbsp;</p>
<p><strong class="example">Example 1:</strong></p>
<pre><code><strong>Input:</strong> paths = ["root/a 1.txt(abcd) 2.txt(efgh)","root/c 3.txt(abcd)","root/c/d 4.txt(efgh)","root 4.txt(efgh)"]
<strong>Output:</strong> [["root/a/2.txt","root/c/d/4.txt","root/4.txt"],["root/a/1.txt","root/c/3.txt"]]</code></pre><p><strong class="example">Example 2:</strong></p>
<pre><code><strong>Input:</strong> paths = ["root/a 1.txt(abcd) 2.txt(efgh)","root/c 3.txt(abcd)","root/c/d 4.txt(efgh)"]
<strong>Output:</strong> [["root/a/2.txt","root/c/d/4.txt"],["root/a/1.txt","root/c/3.txt"]]</code></pre>
<p>&nbsp;</p>
<p><strong>Constraints:</strong></p>
<ul>
  <li><code>1 &lt;= paths.length &lt;= 2 * 10<sup>4</sup></code></li>
  <li><code>1 &lt;= paths[i].length &lt;= 3000</code></li>
  <li><code>1 &lt;= sum(paths[i].length) &lt;= 5 * 10<sup>5</sup></code></li>
  <li><code>paths[i]</code> consist of English letters, digits, <code>&#39;/&#39;</code>, <code>&#39;.&#39;</code>, <code>&#39;(&#39;</code>, <code>&#39;)&#39;</code>, and <code>&#39; &#39;</code>.</li>
  <li>You may assume no files or directories share the same name in the same directory.</li>
  <li>You may assume each given directory info represents a unique directory. A single blank space separates the directory path and file info.</li>
</ul>
<p>&nbsp;</p>
<p><strong>Follow up:</strong></p>
<ul>
  <li>Imagine you are given a real file system, how will you search files? DFS or BFS?</li>
  <li>If the file content is very large (GB level), how will you modify your solution?</li>
  <li>If you can only read the file by 1kb each time, how will you modify your solution?</li>
  <li>What is the time complexity of your modified solution? What is the most time-consuming part and memory-consuming part of it? How to optimize?</li>
  <li>How to make sure the duplicated files you find are not false positive?</li>
</ul>

## Solution

**题目描述**

给定一个文件系统，其中包含许多文件，文件以路径和内容的形式给出。要求找到文件系统中的重复文件。重复文件指的是具有相同内容的文件，返回所有重复文件的路径集合。

**解题思路**

1. 哈希表
   - 遍历所有文件，将文件内容作为键，文件路径作为值，存入哈希表中
   - 如果哈希表中已经存在该文件内容，则将该文件路径加入到结果集中
   - 时间复杂度：假设文件系统中有 N 个文件，每个文件的平均大小为 M，构建哈希表的时间复杂度为 O(NM)，遍历哈希表的时间复杂度为 O(N)，因此总体时间复杂度为 O(NM)。
   - 空间复杂度：哈希表的空间复杂度为 O(N*M)，存储结果的空间复杂度为 O(N)。
2. 哈希表+istringstream
   - 思路同上，不同的是使用istringstream来分割文件内容
3. 哈希表+MD5
   - 遍历所有文件，将文件内容的哈希值作为键，文件路径作为值，存入哈希表中
   - 时间复杂度：假设文件系统中有 N 个文件，每个文件的平均大小为 M，构建哈希表的时间复杂度为 O(NM)，遍历哈希表的时间复杂度为 O(N)，因此总体时间复杂度为 O(NM)。
   - 空间复杂度：哈希表的空间复杂度为 O(N*M)，存储结果的空间复杂度为 O(N)。
